{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed482ba",
   "metadata": {},
   "source": [
    "# NRELのAD判定を行う\n",
    "- 学習したGNN(`NREL_multi_task.ipynb`)のcheckpointを読み込んで、AD判定を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4be9cb",
   "metadata": {},
   "source": [
    "## ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3442df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Any, Dict, List, Optional, Tuple, Callable\n",
    "\n",
    "from rdkit import Chem\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_add_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e1bab",
   "metadata": {},
   "source": [
    "## 前処理・モデル構造再定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc59f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports/definitions OK\n"
     ]
    }
   ],
   "source": [
    "# ---------- (A) same constants as training ----------\n",
    "MAX_ATOMIC_NUM = 100\n",
    "MAX_DEGREE = 5\n",
    "\n",
    "BOND_TYPES = {\n",
    "    Chem.rdchem.BondType.SINGLE: 0,\n",
    "    Chem.rdchem.BondType.DOUBLE: 1,\n",
    "    Chem.rdchem.BondType.TRIPLE: 2,\n",
    "    Chem.rdchem.BondType.AROMATIC: 3,\n",
    "}\n",
    "NUM_BOND_TYPES = 4\n",
    "\n",
    "MIN_FC, MAX_FC = -2, 2\n",
    "FC_OFFSET = -MIN_FC\n",
    "NUM_FC = (MAX_FC - MIN_FC + 1)\n",
    "\n",
    "HYB_MAP = {\n",
    "    Chem.rdchem.HybridizationType.SP: 0,\n",
    "    Chem.rdchem.HybridizationType.SP2: 1,\n",
    "    Chem.rdchem.HybridizationType.SP3: 2,\n",
    "    Chem.rdchem.HybridizationType.SP3D: 3,\n",
    "    Chem.rdchem.HybridizationType.SP3D2: 4,\n",
    "}\n",
    "HYB_UNKNOWN = 5\n",
    "NUM_HYB = 6\n",
    "\n",
    "def atom_features(atom: Chem.rdchem.Atom) -> torch.Tensor:\n",
    "    atomic_num = min(atom.GetAtomicNum(), MAX_ATOMIC_NUM)\n",
    "    degree = min(atom.GetDegree(), MAX_DEGREE)\n",
    "    aromatic = int(atom.GetIsAromatic())\n",
    "\n",
    "    formal_charge = atom.GetFormalCharge()\n",
    "    formal_charge = max(MIN_FC, min(formal_charge, MAX_FC)) + FC_OFFSET  # 0..4\n",
    "\n",
    "    hyb_idx = HYB_MAP.get(atom.GetHybridization(), HYB_UNKNOWN)\n",
    "\n",
    "    return torch.tensor([atomic_num, degree, aromatic, formal_charge, hyb_idx], dtype=torch.long)\n",
    "\n",
    "def bond_features(bond: Chem.rdchem.Bond) -> torch.Tensor:\n",
    "    bond_type = BOND_TYPES.get(bond.GetBondType(), 0)\n",
    "    conjugated = int(bond.GetIsConjugated())\n",
    "    in_ring = int(bond.IsInRing())\n",
    "    return torch.tensor([bond_type, conjugated, in_ring], dtype=torch.long)\n",
    "\n",
    "def canonicalize_smiles(smi: str) -> Optional[str]:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return Chem.MolToSmiles(mol, canonical=True)\n",
    "\n",
    "def smiles_to_pyg_discrete_v2(smiles: str):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    x = torch.stack([atom_features(a) for a in mol.GetAtoms()], dim=0)  # [N, 5]\n",
    "\n",
    "    edge_index_list, edge_attr_list = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        bf = bond_features(bond)\n",
    "        edge_index_list += [[i, j], [j, i]]\n",
    "        edge_attr_list  += [bf, bf]\n",
    "\n",
    "    if len(edge_index_list) == 0:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_attr  = torch.empty((0, 3), dtype=torch.long)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "        edge_attr  = torch.stack(edge_attr_list, dim=0)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    data.smiles = smiles\n",
    "    return data\n",
    "\n",
    "def serializable_to_scalers(d: Dict[str, Dict[str, float]]) -> Dict[str, Tuple[float, float]]:\n",
    "    return {k: (float(v[\"median\"]), float(v[\"iqr\"])) for k, v in d.items()}\n",
    "\n",
    "def inverse_robust_scalar(x_scaled: float, med: float, iqr: float) -> float:\n",
    "    return float(x_scaled * iqr + med)\n",
    "\n",
    "# ---------- (B) Model definition (must match training) ----------\n",
    "class EdgeCondLinearLayer(MessagePassing):\n",
    "    def __init__(self, hidden_dim: int, num_bond_types: int):\n",
    "        super().__init__(aggr=\"add\")\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_bond_types = num_bond_types\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(num_bond_types, hidden_dim, hidden_dim))\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "        self.gru = nn.GRUCell(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, bond_type):\n",
    "        m = self.propagate(edge_index, x=x, bond_type=bond_type)\n",
    "        x_out = self.gru(m, x)\n",
    "        return x_out\n",
    "\n",
    "    def message(self, x_j, bond_type):\n",
    "        bt = bond_type.clamp(0, self.num_bond_types - 1)\n",
    "        W_bt = self.W[bt]  # [E,H,H]\n",
    "        m = torch.bmm(W_bt, x_j.unsqueeze(-1)).squeeze(-1)\n",
    "        return m\n",
    "\n",
    "class MPNNRegressor(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 128, num_layers: int = 3, num_targets: int = 3, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_atomic = nn.Embedding(MAX_ATOMIC_NUM + 1, 64)\n",
    "        self.emb_degree = nn.Embedding(MAX_DEGREE + 1, 16)\n",
    "        self.emb_aroma  = nn.Embedding(2, 8)\n",
    "        self.emb_fc     = nn.Embedding(NUM_FC, 8)\n",
    "        self.emb_hyb    = nn.Embedding(NUM_HYB, 8)\n",
    "\n",
    "        node_in_dim = 64 + 16 + 8 + 8 + 8  # 104\n",
    "        self.node_proj = nn.Linear(node_in_dim, hidden_dim)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            EdgeCondLinearLayer(hidden_dim=hidden_dim, num_bond_types=NUM_BOND_TYPES)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.fp_dim = 1024\n",
    "        self.node_to_fp = nn.Linear(hidden_dim, self.fp_dim)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.fp_dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.out = nn.Linear(256, num_targets)\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr  = data.edge_attr\n",
    "        batch      = data.batch\n",
    "\n",
    "        atomic_num      = x[:, 0].clamp(0, MAX_ATOMIC_NUM)\n",
    "        degree          = x[:, 1].clamp(0, MAX_DEGREE)\n",
    "        aromatic        = x[:, 2].clamp(0, 1)\n",
    "        formal_charge   = x[:, 3].clamp(0, NUM_FC - 1)\n",
    "        hybridization   = x[:, 4].clamp(0, NUM_HYB - 1)\n",
    "\n",
    "        h = torch.cat([\n",
    "            self.emb_atomic(atomic_num),\n",
    "            self.emb_degree(degree),\n",
    "            self.emb_aroma(aromatic),\n",
    "            self.emb_fc(formal_charge),\n",
    "            self.emb_hyb(hybridization),\n",
    "        ], dim=-1)\n",
    "\n",
    "        h = self.node_proj(h)\n",
    "\n",
    "        bond_type = edge_attr[:, 0].clamp(0, NUM_BOND_TYPES - 1)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, edge_index, bond_type)\n",
    "\n",
    "        h_fp = self.node_to_fp(h)\n",
    "        g    = global_add_pool(h_fp, batch)\n",
    "\n",
    "        z = self.bn1(self.fc1(g))\n",
    "        z = F.relu(z)\n",
    "        if self.dropout > 0:\n",
    "            z = F.dropout(z, p=self.dropout, training=self.training)\n",
    "\n",
    "        z = self.bn2(self.fc2(z))\n",
    "        z = F.relu(z)\n",
    "        if self.dropout > 0:\n",
    "            z = F.dropout(z, p=self.dropout, training=self.training)\n",
    "\n",
    "        out = self.out(z)\n",
    "        return out\n",
    "\n",
    "class GenericGNNPredictor:\n",
    "    def __init__(self, ckpt_path: str, device: Optional[torch.device] = None):\n",
    "        self.ckpt_path = ckpt_path\n",
    "        self.device = device if device is not None else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        payload = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "        self.dataset_name = payload.get(\"dataset_name\", \"unknown\")\n",
    "        self.model_config = payload[\"model_config\"]\n",
    "        self.preprocess_config = payload[\"preprocess_config\"]\n",
    "        self.scalers = serializable_to_scalers(payload[\"scalers\"])\n",
    "        self.target_cols = list(self.model_config[\"target_cols\"])\n",
    "        self.num_targets = int(self.model_config[\"num_targets\"])\n",
    "\n",
    "        # build model\n",
    "        self.model = MPNNRegressor(\n",
    "            hidden_dim=int(self.model_config[\"hidden_dim\"]),\n",
    "            num_layers=int(self.model_config[\"num_layers\"]),\n",
    "            num_targets=int(self.model_config[\"num_targets\"]),\n",
    "            dropout=float(self.model_config.get(\"dropout\", 0.0)),\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.model.load_state_dict(payload[\"state_dict\"])\n",
    "        self.model.eval()\n",
    "\n",
    "        self.do_canonicalize = bool(self.preprocess_config.get(\"smiles_canonicalize\", True))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_smiles(self, smiles: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        1つの SMILES に対して GNN 推論を行い、\n",
    "        robust scaling を逆変換した raw 値を返す。\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict:\n",
    "            {\n",
    "              \"ok\": bool,\n",
    "              \"smiles_in\": 入力 SMILES,\n",
    "              \"smiles_used\": 正規化後 SMILES,\n",
    "              \"pred_raw\": {target: value}\n",
    "            }\n",
    "        \"\"\"\n",
    "\n",
    "        smi_in = smiles          # ユーザ入力そのまま\n",
    "        smi = smiles\n",
    "\n",
    "        # --- canonical SMILES 化 ---\n",
    "        if self.do_canonicalize:\n",
    "            smi2 = canonicalize_smiles(smi)\n",
    "            if smi2 is None:\n",
    "                # RDKit で解釈不能な SMILES\n",
    "                return {\n",
    "                    \"ok\": False,\n",
    "                    \"smiles_in\": smi_in,\n",
    "                    \"error\": \"Invalid SMILES\"\n",
    "                }\n",
    "            smi = smi2\n",
    "\n",
    "        # --- SMILES → PyG Data ---\n",
    "        data = smiles_to_pyg_discrete_v2(smi)\n",
    "        if data is None:\n",
    "            return {\n",
    "                \"ok\": False,\n",
    "                \"smiles_in\": smi_in,\n",
    "                \"smiles_used\": smi,\n",
    "                \"error\": \"Failed to build graph\"\n",
    "            }\n",
    "\n",
    "        # --- batch 化（1分子だけだが PyG の都合上必要） ---\n",
    "        batch = next(\n",
    "            iter(DataLoader([data], batch_size=1, shuffle=False))\n",
    "        ).to(self.device)\n",
    "\n",
    "        # --- GNN 推論（scaled 出力） ---\n",
    "        pred_scaled = self.model(batch).detach().cpu().view(-1)\n",
    "\n",
    "        # --- robust scaling を逆変換 ---\n",
    "        pred_raw_dict = {}\n",
    "        for i, t in enumerate(self.target_cols):\n",
    "            med, iqr = self.scalers[t]\n",
    "            pred_raw_dict[t] = inverse_robust_scalar(\n",
    "                float(pred_scaled[i].item()), med, iqr\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"ok\": True,\n",
    "            \"smiles_in\": smi_in,\n",
    "            \"smiles_used\": smi,\n",
    "            \"pred_raw\": pred_raw_dict\n",
    "        }\n",
    "\n",
    "def load_predictor_generic(\n",
    "    dataset_name: str,\n",
    "    save_root: str = \"models\",\n",
    "    ckpt_name: str = \"checkpoint.pt\",\n",
    "    device: Optional[torch.device] = None\n",
    ") -> GenericGNNPredictor:\n",
    "    \"\"\"\n",
    "    models/{dataset_name}/{ckpt_name} にある checkpoint から\n",
    "    GenericGNNPredictor を生成するユーティリティ関数。\n",
    "\n",
    "    GUI / notebook / CLI で共通 API にするための薄いラッパー。\n",
    "    \"\"\"\n",
    "    ckpt_path = os.path.join(save_root, dataset_name, ckpt_name)\n",
    "    return GenericGNNPredictor(ckpt_path=ckpt_path, device=device)\n",
    "\n",
    "print(\"Imports/definitions OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab04873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded predictor for dataset: nrel\n",
      "Targets: ['gap', 'homo', 'lumo', 'spectral_overlap', 'homo_extrapolated', 'lumo_extrapolated', 'gap_extrapolated', 'optical_lumo_extrapolated']\n",
      "Prediction result:\n",
      "{'ok': True, 'smiles_in': 'CCO', 'smiles_used': 'CCO', 'pred_raw': {'gap': 5.1179975324630735, 'homo': -6.481625464229649, 'lumo': -0.7308945234565236, 'spectral_overlap': -422.84538336668584, 'homo_extrapolated': -5.616125647804598, 'lumo_extrapolated': -2.1236128026149608, 'gap_extrapolated': 3.174334164434671, 'optical_lumo_extrapolated': -2.436118149549048}}\n"
     ]
    }
   ],
   "source": [
    "# Load predictor & sanity check\n",
    "\n",
    "# checkpoint から predictor をロード\n",
    "predictor = load_predictor_generic(\n",
    "    dataset_name=\"nrel\",\n",
    "    save_root=\"models\",\n",
    "    ckpt_name=\"checkpoint.pt\",\n",
    ")\n",
    "\n",
    "print(\"Loaded predictor for dataset:\", predictor.dataset_name)\n",
    "print(\"Targets:\", predictor.target_cols)\n",
    "\n",
    "# 簡単なSMILESで予測テスト\n",
    "res = predictor.predict_smiles(\"CCO\")  # ethanol\n",
    "\n",
    "print(\"Prediction result:\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b28d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: nrel\n",
      "model_name  : mpnn_edgecond_gru\n",
      "preprocess_name: discrete_atom_bond_v2\n",
      "canonicalize: True\n",
      "matches expected? True\n"
     ]
    }
   ],
   "source": [
    "# Check preprocess consistency from checkpoint\n",
    "ckpt_path = os.path.join(\"models\", \"nrel\", \"checkpoint.pt\")\n",
    "payload = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "print(\"dataset_name:\", payload.get(\"dataset_name\"))\n",
    "print(\"model_name  :\", payload.get(\"model_config\", {}).get(\"model_name\"))\n",
    "print(\"preprocess_name:\", payload.get(\"preprocess_config\", {}).get(\"preprocess_name\"))\n",
    "\n",
    "# 念のため、ここが True になっているか確認\n",
    "print(\"canonicalize:\", payload.get(\"preprocess_config\", {}).get(\"smiles_canonicalize\", None))\n",
    "\n",
    "# 期待している前処理名\n",
    "expected = \"discrete_atom_bond_v2\"\n",
    "print(\"matches expected?\", payload.get(\"preprocess_config\", {}).get(\"preprocess_name\") == expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089bb2e7",
   "metadata": {},
   "source": [
    "## グラフ埋め込みを抽出・AD範囲決定・AD判定\n",
    "- readout関数の出力(global_add_pool後の出力)、`g(1024, )`を取り出して、ここからADの範囲を作る\n",
    "- 手順として、\n",
    "\n",
    "1. 学習データにおけるgを取り出し、マハラノビス距離を計算する\n",
    "2. テストデータのgを取り出し、マハラノビス距離を計算する\n",
    "3. **学習データにおけるマハラノビス距離のうち、上位2%をAD外として、テストデータに当てはめ、AD内外を判定する**\n",
    "\n",
    "- マハラノビス距離を使う理由として、ユークリッド距離に比べ、データの分布（`共分散行列`）を考慮することで、データのばらつき具合や相関係数を反映した距離を計算できるため\n",
    "- OCSVMでも良いが、こちらはハイパーパラメータに敏感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c01b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g shape: (1024,)\n",
      "g[:5] = [-13.123536    -0.49069118  -4.005358     6.9682674    7.9609346 ]\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def embed_smiles(predictor, smiles: str):\n",
    "    \"\"\"\n",
    "    学習済みGNNから、分子fingerprint g（1024次元）を取得する。\n",
    "    予測ヘッド(MLP)は通さない。AD用。\n",
    "    \"\"\"\n",
    "    smi = smiles\n",
    "    if predictor.do_canonicalize:\n",
    "        smi2 = canonicalize_smiles(smi)\n",
    "        if smi2 is None:\n",
    "            return None\n",
    "        smi = smi2\n",
    "\n",
    "    data = smiles_to_pyg_discrete_v2(smi)\n",
    "    if data is None:\n",
    "        return None\n",
    "\n",
    "    # Batch of 1\n",
    "    batch = next(iter(DataLoader([data], batch_size=1, shuffle=False))).to(predictor.device)\n",
    "\n",
    "    m = predictor.model\n",
    "    m.eval()\n",
    "\n",
    "    # --- forward の readout 直前まで ---\n",
    "    x = batch.x\n",
    "    edge_index = batch.edge_index\n",
    "    edge_attr  = batch.edge_attr\n",
    "    batch_vec  = batch.batch\n",
    "\n",
    "    atomic_num      = x[:, 0].clamp(0, MAX_ATOMIC_NUM)\n",
    "    degree          = x[:, 1].clamp(0, MAX_DEGREE)\n",
    "    aromatic        = x[:, 2].clamp(0, 1)\n",
    "    formal_charge   = x[:, 3].clamp(0, NUM_FC - 1)\n",
    "    hybridization   = x[:, 4].clamp(0, NUM_HYB - 1)\n",
    "\n",
    "    h = torch.cat([\n",
    "        m.emb_atomic(atomic_num),\n",
    "        m.emb_degree(degree),\n",
    "        m.emb_aroma(aromatic),\n",
    "        m.emb_fc(formal_charge),\n",
    "        m.emb_hyb(hybridization),\n",
    "    ], dim=-1)\n",
    "\n",
    "    h = m.node_proj(h)\n",
    "\n",
    "    bond_type = edge_attr[:, 0].clamp(0, NUM_BOND_TYPES - 1)\n",
    "    \n",
    "    for layer in m.layers:\n",
    "        h = layer(h, edge_index, bond_type)\n",
    "\n",
    "    h_fp = m.node_to_fp(h)                 # [N, 1024]\n",
    "    g    = global_add_pool(h_fp, batch_vec)  # [1, 1024]\n",
    "\n",
    "    return g.cpu().view(-1).numpy()         # (1024,)\n",
    "\n",
    "\n",
    "# ---- 動作確認 ----\n",
    "g = embed_smiles(predictor, \"CCO\")\n",
    "\n",
    "print(\"g shape:\", None if g is None else g.shape)\n",
    "print(\"g[:5] =\", g[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e48594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num smiles: 43468 example: COC(=O)c1nc2c(-c3ccc(-c4cccs4)s3)sc(-c3cccs3)c2o1\n",
      "embedded: 43468 / 43468\n",
      "bad: 0\n",
      "Saved:\n",
      " - models/ad_artifacts/nrel/G_train.npy\n",
      " - models/ad_artifacts/nrel/train_smiles_ok.csv\n",
      " - models/ad_artifacts/nrel/train_smiles_bad.csv\n"
     ]
    }
   ],
   "source": [
    "# 学習データにて、smilesの埋め込みを計算し、matrix G(学習データにおけるgの集まり) を保存する\n",
    "\n",
    "train_csv_path = 'data/NREL/nrel_train_processed.csv'\n",
    "smiles_col = 'smile'\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "smiles_list = train_df[smiles_col].astype(str).tolist()\n",
    "\n",
    "print(\"num smiles:\", len(smiles_list), \"example:\", smiles_list[0])\n",
    "\n",
    "# 埋め込みを作る（失敗SMILESは除外していく）\n",
    "G_list = []\n",
    "ok_smiles = []\n",
    "bad_smiles = []\n",
    "\n",
    "for smi in smiles_list:\n",
    "    g = embed_smiles(predictor, smi)\n",
    "    if g is None:\n",
    "        bad_smiles.append(smi)\n",
    "        continue\n",
    "    G_list.append(g)\n",
    "    ok_smiles.append(smi)\n",
    "\n",
    "G = np.stack(G_list, axis=0)  # (N_ok, 1024)\n",
    "\n",
    "print(\"embedded:\", G.shape[0], \"/\", len(smiles_list))\n",
    "print(\"bad:\", len(bad_smiles))\n",
    "\n",
    "# 保存（AD notebook間で使い回せる）\n",
    "out_dir = \"models/ad_artifacts/nrel\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(out_dir, \"G_train.npy\"), G)\n",
    "\n",
    "# 後で対応づけできるよう、OK/NG SMILESも保存\n",
    "pd.Series(ok_smiles, name=\"smiles\").to_csv(os.path.join(out_dir, \"train_smiles_ok.csv\"), index=False)\n",
    "pd.Series(bad_smiles, name=\"smiles\").to_csv(os.path.join(out_dir, \"train_smiles_bad.csv\"), index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", os.path.join(out_dir, \"G_train.npy\"))\n",
    "print(\" -\", os.path.join(out_dir, \"train_smiles_ok.csv\"))\n",
    "print(\" -\", os.path.join(out_dir, \"train_smiles_bad.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c7f0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_tr shape: (43468, 1024)\n",
      "Mahalanobis stats (train): min/mean/max = 30.10624160556471 124.61417260630242 1962.6205267782075\n",
      "thr (top 2.0%): 316.6998296135209\n",
      "train out-rate: 0.020014723474740037\n",
      "Saved:\n",
      " - md_mu.npy / md_inv_cov.npy / md_thr.npy\n",
      " - md_median.npy / md_iqr.npy\n"
     ]
    }
   ],
   "source": [
    "# マハラノビス距離の計算と閾値設定\n",
    "\n",
    "# 1) load embeddings\n",
    "ad_dir = \"models/ad_artifacts/nrel\"\n",
    "G_tr = np.load(os.path.join(ad_dir, \"G_train.npy\"))   # (N, 1024)\n",
    "print(\"G_tr shape:\", G_tr.shape)\n",
    "\n",
    "# 2) robust scaling parameters (median / IQR)\n",
    "median = np.median(G_tr, axis=0)\n",
    "q1 = np.percentile(G_tr, 25, axis=0)\n",
    "q3 = np.percentile(G_tr, 75, axis=0)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# safety: iqr == 0 -> 1.0\n",
    "iqr_safe = np.where(iqr == 0.0, 1.0, iqr)\n",
    "\n",
    "# 3) robust-standardize\n",
    "G_s = (G_tr - median) / iqr_safe\n",
    "\n",
    "# 4) estimate mu/cov in standardized space\n",
    "mu = G_s.mean(axis=0)\n",
    "X  = G_s - mu\n",
    "\n",
    "# 共分散行列\n",
    "cov = np.cov(X, rowvar=False)\n",
    "eps = 1e-3\n",
    "cov += eps * np.eye(cov.shape[0])\n",
    "inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "# 5) Mahalanobis distance on train\n",
    "md_tr = np.einsum(\"bi,ij,bj->b\", X, inv_cov, X)\n",
    "\n",
    "# 6) threshold: top 2% as out (same as ZINC)\n",
    "out_percent = 2.0\n",
    "thr = float(np.percentile(md_tr, 100.0 - out_percent))\n",
    "\n",
    "print(\"Mahalanobis stats (train): min/mean/max =\", md_tr.min(), md_tr.mean(), md_tr.max())\n",
    "print(f\"thr (top {out_percent}%):\", thr)\n",
    "print(\"train out-rate:\", np.mean(md_tr > thr))\n",
    "\n",
    "# 7) save artifacts (numpy-only)\n",
    "np.save(os.path.join(ad_dir, \"md_mu.npy\"), mu)\n",
    "np.save(os.path.join(ad_dir, \"md_inv_cov.npy\"), inv_cov)\n",
    "np.save(os.path.join(ad_dir, \"md_thr.npy\"), np.array([thr]))\n",
    "\n",
    "np.save(os.path.join(ad_dir, \"md_median.npy\"), median)\n",
    "np.save(os.path.join(ad_dir, \"md_iqr.npy\"), iqr_safe)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - md_mu.npy / md_inv_cov.npy / md_thr.npy\")\n",
    "print(\" - md_median.npy / md_iqr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8c3866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: ['gap', 'homo', 'lumo', 'spectral_overlap', 'homo_extrapolated', 'lumo_extrapolated', 'gap_extrapolated', 'optical_lumo_extrapolated']\n",
      "TEST embedded: 5434 / 5434 bad: 0\n",
      "AD-out rate (test): 0.020610967979389033\n",
      "\n",
      "Macro-MAE (raw) by AD label\n",
      "  in : mean = 31.900016066784897 n = 5322\n",
      "  out: mean = 41.417406725555345 n = 112\n",
      "\n",
      "Per-target MAE (raw) by AD label\n",
      "         gap | in: 0.0778 | out: 0.1125\n",
      "        homo | in: 0.0571 | out: 0.0965\n",
      "        lumo | in: 0.0662 | out: 0.1079\n",
      "  spectral_overlap | in: 254.6899 | out: 330.6000\n",
      "  homo_extrapolated | in: 0.0734 | out: 0.1134\n",
      "  lumo_extrapolated | in: 0.0751 | out: 0.0914\n",
      "  gap_extrapolated | in: 0.0883 | out: 0.1133\n",
      "  optical_lumo_extrapolated | in: 0.0722 | out: 0.1042\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smile</th>\n",
       "      <th>gap</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>spectral_overlap</th>\n",
       "      <th>homo_extrapolated</th>\n",
       "      <th>lumo_extrapolated</th>\n",
       "      <th>gap_extrapolated</th>\n",
       "      <th>optical_lumo_extrapolated</th>\n",
       "      <th>pred_gap</th>\n",
       "      <th>pred_homo</th>\n",
       "      <th>pred_lumo</th>\n",
       "      <th>pred_spectral_overlap</th>\n",
       "      <th>pred_homo_extrapolated</th>\n",
       "      <th>pred_lumo_extrapolated</th>\n",
       "      <th>pred_gap_extrapolated</th>\n",
       "      <th>pred_optical_lumo_extrapolated</th>\n",
       "      <th>md</th>\n",
       "      <th>ad_label</th>\n",
       "      <th>mae_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CN1C(=O)c2cn(C)c(-c3cc4c(s3)c3sc(-c5cc6c(ccc7n...</td>\n",
       "      <td>1.9039</td>\n",
       "      <td>-5.058052</td>\n",
       "      <td>-2.896652</td>\n",
       "      <td>2891.449538</td>\n",
       "      <td>-4.927982</td>\n",
       "      <td>-3.174208</td>\n",
       "      <td>1.4155</td>\n",
       "      <td>-3.512482</td>\n",
       "      <td>1.883357</td>\n",
       "      <td>-5.048064</td>\n",
       "      <td>-2.851986</td>\n",
       "      <td>2881.379974</td>\n",
       "      <td>-4.828990</td>\n",
       "      <td>-3.134547</td>\n",
       "      <td>1.367921</td>\n",
       "      <td>-3.462917</td>\n",
       "      <td>82.689315</td>\n",
       "      <td>in</td>\n",
       "      <td>1.297570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cn1c(=O)c2cc(F)c3c(=O)n(C)c(=O)c4c(-c5scc6c5C(...</td>\n",
       "      <td>1.9486</td>\n",
       "      <td>-5.993579</td>\n",
       "      <td>-3.588365</td>\n",
       "      <td>279.676231</td>\n",
       "      <td>-5.940245</td>\n",
       "      <td>-3.635169</td>\n",
       "      <td>1.8720</td>\n",
       "      <td>-4.068245</td>\n",
       "      <td>2.120014</td>\n",
       "      <td>-6.247611</td>\n",
       "      <td>-3.511788</td>\n",
       "      <td>274.469807</td>\n",
       "      <td>-6.074170</td>\n",
       "      <td>-3.616370</td>\n",
       "      <td>1.894259</td>\n",
       "      <td>-4.184565</td>\n",
       "      <td>97.256361</td>\n",
       "      <td>in</td>\n",
       "      <td>0.749968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cn1cc2c(c1-c1sc3c(c(F)c(F)c4c(C(F)(F)F)csc43)c...</td>\n",
       "      <td>3.3019</td>\n",
       "      <td>-5.529081</td>\n",
       "      <td>-1.778808</td>\n",
       "      <td>211.826445</td>\n",
       "      <td>-5.380507</td>\n",
       "      <td>-2.481406</td>\n",
       "      <td>2.5025</td>\n",
       "      <td>-2.878007</td>\n",
       "      <td>3.078325</td>\n",
       "      <td>-5.484511</td>\n",
       "      <td>-1.881059</td>\n",
       "      <td>247.634294</td>\n",
       "      <td>-5.369314</td>\n",
       "      <td>-2.405537</td>\n",
       "      <td>2.596289</td>\n",
       "      <td>-2.774814</td>\n",
       "      <td>92.462092</td>\n",
       "      <td>in</td>\n",
       "      <td>4.557786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN1C(=O)c2cc(C(F)(F)F)c3c4c(c(-c5cccc6nsnc56)c...</td>\n",
       "      <td>2.1428</td>\n",
       "      <td>-6.582162</td>\n",
       "      <td>-3.847962</td>\n",
       "      <td>191.814424</td>\n",
       "      <td>-6.417261</td>\n",
       "      <td>-3.859935</td>\n",
       "      <td>2.0126</td>\n",
       "      <td>-4.404661</td>\n",
       "      <td>2.078816</td>\n",
       "      <td>-6.598798</td>\n",
       "      <td>-3.948571</td>\n",
       "      <td>413.752173</td>\n",
       "      <td>-6.453630</td>\n",
       "      <td>-3.929871</td>\n",
       "      <td>2.069413</td>\n",
       "      <td>-4.386049</td>\n",
       "      <td>139.515832</td>\n",
       "      <td>in</td>\n",
       "      <td>27.787588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CN1C(=O)C2=C(c3ccc(-c4ccc(-c5ccc(-c6ccc7c(c6)C...</td>\n",
       "      <td>1.8553</td>\n",
       "      <td>-4.672467</td>\n",
       "      <td>-2.642770</td>\n",
       "      <td>10019.222905</td>\n",
       "      <td>-4.656140</td>\n",
       "      <td>-2.658008</td>\n",
       "      <td>1.7825</td>\n",
       "      <td>-2.873640</td>\n",
       "      <td>1.755233</td>\n",
       "      <td>-4.677318</td>\n",
       "      <td>-2.712527</td>\n",
       "      <td>9642.344788</td>\n",
       "      <td>-4.632778</td>\n",
       "      <td>-2.745082</td>\n",
       "      <td>1.594149</td>\n",
       "      <td>-3.038425</td>\n",
       "      <td>135.155273</td>\n",
       "      <td>in</td>\n",
       "      <td>47.189545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cn1cc2c(c1-c1cccc3nc4c5ccccc5c5ccccc5c4nc13)OC...</td>\n",
       "      <td>2.2701</td>\n",
       "      <td>-4.973425</td>\n",
       "      <td>-2.171196</td>\n",
       "      <td>290.695315</td>\n",
       "      <td>-4.294228</td>\n",
       "      <td>-2.264803</td>\n",
       "      <td>1.5951</td>\n",
       "      <td>-2.699128</td>\n",
       "      <td>2.116642</td>\n",
       "      <td>-4.977225</td>\n",
       "      <td>-2.335914</td>\n",
       "      <td>407.860522</td>\n",
       "      <td>-4.429080</td>\n",
       "      <td>-2.453977</td>\n",
       "      <td>1.622339</td>\n",
       "      <td>-2.806809</td>\n",
       "      <td>101.929163</td>\n",
       "      <td>in</td>\n",
       "      <td>14.743266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cc1csc(-c2ccc(-c3cc4c5nn(C)nc5c5cc(-c6cccs6)sc...</td>\n",
       "      <td>2.6844</td>\n",
       "      <td>-4.960363</td>\n",
       "      <td>-2.007928</td>\n",
       "      <td>2302.958874</td>\n",
       "      <td>-4.602261</td>\n",
       "      <td>-2.526033</td>\n",
       "      <td>1.6816</td>\n",
       "      <td>-2.920661</td>\n",
       "      <td>2.635558</td>\n",
       "      <td>-4.950360</td>\n",
       "      <td>-1.990014</td>\n",
       "      <td>2254.460934</td>\n",
       "      <td>-4.590778</td>\n",
       "      <td>-2.545426</td>\n",
       "      <td>1.687141</td>\n",
       "      <td>-2.901878</td>\n",
       "      <td>96.885230</td>\n",
       "      <td>in</td>\n",
       "      <td>6.078738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cc1c2nc(-c3cccs3)n(C)c2c(C)c2c1nc(-c1ccc(-c3cc...</td>\n",
       "      <td>1.2892</td>\n",
       "      <td>-5.277104</td>\n",
       "      <td>-3.704286</td>\n",
       "      <td>1414.824725</td>\n",
       "      <td>-5.258600</td>\n",
       "      <td>-3.825648</td>\n",
       "      <td>1.3164</td>\n",
       "      <td>-3.942200</td>\n",
       "      <td>1.289674</td>\n",
       "      <td>-5.263706</td>\n",
       "      <td>-3.702511</td>\n",
       "      <td>1536.217899</td>\n",
       "      <td>-5.230779</td>\n",
       "      <td>-3.816379</td>\n",
       "      <td>1.249489</td>\n",
       "      <td>-3.982984</td>\n",
       "      <td>146.564151</td>\n",
       "      <td>in</td>\n",
       "      <td>15.194201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cc1nc2c(-c3ccc(-c4cc5c(C)c6sccc6c(C)c5s4)n3C)s...</td>\n",
       "      <td>2.7696</td>\n",
       "      <td>-4.731515</td>\n",
       "      <td>-1.559212</td>\n",
       "      <td>3062.791642</td>\n",
       "      <td>-4.425659</td>\n",
       "      <td>-1.974458</td>\n",
       "      <td>2.0952</td>\n",
       "      <td>-2.330459</td>\n",
       "      <td>2.803644</td>\n",
       "      <td>-4.619782</td>\n",
       "      <td>-1.467004</td>\n",
       "      <td>3308.841276</td>\n",
       "      <td>-4.561262</td>\n",
       "      <td>-1.735517</td>\n",
       "      <td>2.435672</td>\n",
       "      <td>-2.122544</td>\n",
       "      <td>162.475675</td>\n",
       "      <td>in</td>\n",
       "      <td>30.901319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C/C=C1\\C(=O)c2c(c3cc(-c4ccc(-c5ccc(-c6ccc7c(c6...</td>\n",
       "      <td>2.4775</td>\n",
       "      <td>-5.127713</td>\n",
       "      <td>-2.344805</td>\n",
       "      <td>3580.303419</td>\n",
       "      <td>-5.001997</td>\n",
       "      <td>-2.511339</td>\n",
       "      <td>2.1341</td>\n",
       "      <td>-2.867897</td>\n",
       "      <td>2.490217</td>\n",
       "      <td>-5.114024</td>\n",
       "      <td>-2.319049</td>\n",
       "      <td>3087.596986</td>\n",
       "      <td>-4.966068</td>\n",
       "      <td>-2.477586</td>\n",
       "      <td>2.165468</td>\n",
       "      <td>-2.799376</td>\n",
       "      <td>85.978384</td>\n",
       "      <td>in</td>\n",
       "      <td>61.616021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               smile     gap      homo  \\\n",
       "0  CN1C(=O)c2cn(C)c(-c3cc4c(s3)c3sc(-c5cc6c(ccc7n...  1.9039 -5.058052   \n",
       "1  Cn1c(=O)c2cc(F)c3c(=O)n(C)c(=O)c4c(-c5scc6c5C(...  1.9486 -5.993579   \n",
       "2  Cn1cc2c(c1-c1sc3c(c(F)c(F)c4c(C(F)(F)F)csc43)c...  3.3019 -5.529081   \n",
       "3  CN1C(=O)c2cc(C(F)(F)F)c3c4c(c(-c5cccc6nsnc56)c...  2.1428 -6.582162   \n",
       "4  CN1C(=O)C2=C(c3ccc(-c4ccc(-c5ccc(-c6ccc7c(c6)C...  1.8553 -4.672467   \n",
       "5  Cn1cc2c(c1-c1cccc3nc4c5ccccc5c5ccccc5c4nc13)OC...  2.2701 -4.973425   \n",
       "6  Cc1csc(-c2ccc(-c3cc4c5nn(C)nc5c5cc(-c6cccs6)sc...  2.6844 -4.960363   \n",
       "7  Cc1c2nc(-c3cccs3)n(C)c2c(C)c2c1nc(-c1ccc(-c3cc...  1.2892 -5.277104   \n",
       "8  Cc1nc2c(-c3ccc(-c4cc5c(C)c6sccc6c(C)c5s4)n3C)s...  2.7696 -4.731515   \n",
       "9  C/C=C1\\C(=O)c2c(c3cc(-c4ccc(-c5ccc(-c6ccc7c(c6...  2.4775 -5.127713   \n",
       "\n",
       "       lumo  spectral_overlap  homo_extrapolated  lumo_extrapolated  \\\n",
       "0 -2.896652       2891.449538          -4.927982          -3.174208   \n",
       "1 -3.588365        279.676231          -5.940245          -3.635169   \n",
       "2 -1.778808        211.826445          -5.380507          -2.481406   \n",
       "3 -3.847962        191.814424          -6.417261          -3.859935   \n",
       "4 -2.642770      10019.222905          -4.656140          -2.658008   \n",
       "5 -2.171196        290.695315          -4.294228          -2.264803   \n",
       "6 -2.007928       2302.958874          -4.602261          -2.526033   \n",
       "7 -3.704286       1414.824725          -5.258600          -3.825648   \n",
       "8 -1.559212       3062.791642          -4.425659          -1.974458   \n",
       "9 -2.344805       3580.303419          -5.001997          -2.511339   \n",
       "\n",
       "   gap_extrapolated  optical_lumo_extrapolated  pred_gap  pred_homo  \\\n",
       "0            1.4155                  -3.512482  1.883357  -5.048064   \n",
       "1            1.8720                  -4.068245  2.120014  -6.247611   \n",
       "2            2.5025                  -2.878007  3.078325  -5.484511   \n",
       "3            2.0126                  -4.404661  2.078816  -6.598798   \n",
       "4            1.7825                  -2.873640  1.755233  -4.677318   \n",
       "5            1.5951                  -2.699128  2.116642  -4.977225   \n",
       "6            1.6816                  -2.920661  2.635558  -4.950360   \n",
       "7            1.3164                  -3.942200  1.289674  -5.263706   \n",
       "8            2.0952                  -2.330459  2.803644  -4.619782   \n",
       "9            2.1341                  -2.867897  2.490217  -5.114024   \n",
       "\n",
       "   pred_lumo  pred_spectral_overlap  pred_homo_extrapolated  \\\n",
       "0  -2.851986            2881.379974               -4.828990   \n",
       "1  -3.511788             274.469807               -6.074170   \n",
       "2  -1.881059             247.634294               -5.369314   \n",
       "3  -3.948571             413.752173               -6.453630   \n",
       "4  -2.712527            9642.344788               -4.632778   \n",
       "5  -2.335914             407.860522               -4.429080   \n",
       "6  -1.990014            2254.460934               -4.590778   \n",
       "7  -3.702511            1536.217899               -5.230779   \n",
       "8  -1.467004            3308.841276               -4.561262   \n",
       "9  -2.319049            3087.596986               -4.966068   \n",
       "\n",
       "   pred_lumo_extrapolated  pred_gap_extrapolated  \\\n",
       "0               -3.134547               1.367921   \n",
       "1               -3.616370               1.894259   \n",
       "2               -2.405537               2.596289   \n",
       "3               -3.929871               2.069413   \n",
       "4               -2.745082               1.594149   \n",
       "5               -2.453977               1.622339   \n",
       "6               -2.545426               1.687141   \n",
       "7               -3.816379               1.249489   \n",
       "8               -1.735517               2.435672   \n",
       "9               -2.477586               2.165468   \n",
       "\n",
       "   pred_optical_lumo_extrapolated          md ad_label  mae_macro  \n",
       "0                       -3.462917   82.689315       in   1.297570  \n",
       "1                       -4.184565   97.256361       in   0.749968  \n",
       "2                       -2.774814   92.462092       in   4.557786  \n",
       "3                       -4.386049  139.515832       in  27.787588  \n",
       "4                       -3.038425  135.155273       in  47.189545  \n",
       "5                       -2.806809  101.929163       in  14.743266  \n",
       "6                       -2.901878   96.885230       in   6.078738  \n",
       "7                       -3.982984  146.564151       in  15.194201  \n",
       "8                       -2.122544  162.475675       in  30.901319  \n",
       "9                       -2.799376   85.978384       in  61.616021  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# テストデータに対するAD判定\n",
    "# ---- load AD artifacts (NREL) ----\n",
    "ad_dir = \"models/ad_artifacts/nrel\"\n",
    "\n",
    "mu = np.load(os.path.join(ad_dir, \"md_mu.npy\"))\n",
    "inv_cov = np.load(os.path.join(ad_dir, \"md_inv_cov.npy\"))\n",
    "thr = float(np.load(os.path.join(ad_dir, \"md_thr.npy\"))[0])\n",
    "\n",
    "mean  = np.load(os.path.join(ad_dir, \"md_median.npy\"))\n",
    "scale = np.load(os.path.join(ad_dir, \"md_iqr.npy\"))\n",
    "\n",
    "# safety\n",
    "iqr_safe = np.where(scale == 0.0, 1.0, scale)\n",
    "\n",
    "def mahalanobis_distance_from_g(G, mean, scale, mu, inv_cov):\n",
    "    \"\"\"\n",
    "    G: (N, D) raw embedding\n",
    "    standardize -> subtract mu -> mahalanobis\n",
    "    \"\"\"\n",
    "    Gs = (G - mean) / scale\n",
    "    D = Gs - mu.reshape(1, -1)\n",
    "    md = np.einsum(\"bi,ij,bj->b\", D, inv_cov, D)\n",
    "    return md\n",
    "\n",
    "# ---- load test dataframe (NREL) ----\n",
    "test_csv_path = \"data/NREL/nrel_test_processed.csv\"   # ←ファイル名だけ合わせて\n",
    "smiles_col = \"smile\"                                  # ←あなたの列名に合わせて\n",
    "\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# NRELの目的変数列名\n",
    "target_cols = predictor.target_cols\n",
    "\n",
    "print(\"Targets:\", target_cols)\n",
    "\n",
    "# ---- embed test smiles ----\n",
    "smiles_list = test_df[smiles_col].astype(str).tolist()\n",
    "\n",
    "G_list = []\n",
    "ok_idx = []\n",
    "bad_idx = []\n",
    "\n",
    "for i, smi in enumerate(smiles_list):\n",
    "    g = embed_smiles(predictor, smi)\n",
    "    if g is None:\n",
    "        bad_idx.append(i)\n",
    "        continue\n",
    "    G_list.append(g)\n",
    "    ok_idx.append(i)\n",
    "\n",
    "G_te = np.stack(G_list, axis=0)  # (N_ok, 1024)\n",
    "\n",
    "# ---- AD score & label ----\n",
    "md_te = mahalanobis_distance_from_g(G_te, median, iqr_safe, mu, inv_cov)\n",
    "ad_label = np.where(md_te > thr, \"out\", \"in\")\n",
    "\n",
    "print(\"TEST embedded:\", len(ok_idx), \"/\", len(test_df), \"bad:\", len(bad_idx))\n",
    "print(\"AD-out rate (test):\", np.mean(ad_label == \"out\"))\n",
    "\n",
    "# ---- GNN prediction (raw) for same ok samples ----\n",
    "pred_rows = []\n",
    "for i in ok_idx:\n",
    "    smi = smiles_list[i]\n",
    "    res = predictor.predict_smiles(smi)      # pred_rawを返す実装になっている前提\n",
    "    pred_rows.append(res[\"pred_raw\"])\n",
    "\n",
    "pred_df = pd.DataFrame(pred_rows)  # columns: target_cols\n",
    "\n",
    "# ---- true values (raw) for ok samples ----\n",
    "# processed.csvに raw が入っている前提。もし scaled しか無いならここで止める。\n",
    "true_df = test_df.iloc[ok_idx][target_cols].reset_index(drop=True)\n",
    "\n",
    "# ---- error metrics ----\n",
    "abs_err = (pred_df[target_cols].values - true_df[target_cols].values)\n",
    "mae_each = np.mean(np.abs(abs_err), axis=0)   # per-target MAE\n",
    "mae_macro = np.mean(np.abs(abs_err), axis=1)  # per sample macro-MAE\n",
    "\n",
    "mask_in = (ad_label == \"in\")\n",
    "mask_out = (ad_label == \"out\")\n",
    "\n",
    "print(\"\\nMacro-MAE (raw) by AD label\")\n",
    "print(\"  in : mean =\", mae_macro[mask_in].mean(), \"n =\", int(mask_in.sum()))\n",
    "print(\"  out: mean =\", mae_macro[mask_out].mean(), \"n =\", int(mask_out.sum()))\n",
    "\n",
    "print(\"\\nPer-target MAE (raw) by AD label\")\n",
    "for j, t in enumerate(target_cols):\n",
    "    print(f\"  {t:>10s} | in: {np.mean(np.abs(abs_err[mask_in, j])):.4f} | out: {np.mean(np.abs(abs_err[mask_out, j])):.4f}\")\n",
    "\n",
    "# ---- summary table ----\n",
    "summary = test_df.iloc[ok_idx][[smiles_col] + target_cols].reset_index(drop=True).copy()\n",
    "for t in target_cols:\n",
    "    summary[f\"pred_{t}\"] = pred_df[t].values\n",
    "summary[\"md\"] = md_te\n",
    "summary[\"ad_label\"] = ad_label\n",
    "summary[\"mae_macro\"] = mae_macro\n",
    "\n",
    "display(summary.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0abf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103.87428113 207.11319999 251.38964802 316.69982961 367.71003102]\n",
      "[103.98644558 204.83774985 256.05018122 317.97274284 384.11709076]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "md_tr = mahalanobis_distance_from_g(G_tr, mean, scale, mu, inv_cov)\n",
    "print(np.percentile(md_tr, [50, 90, 95, 98, 99]))\n",
    "\n",
    "# test\n",
    "print(np.percentile(md_te, [50, 90, 95, 98, 99]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
